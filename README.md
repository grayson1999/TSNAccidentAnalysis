í•´ë‹¹ í”„ë¡œê·¸ë¨ì€ [Video-Swin-Transformer](https://github.com/SwinTransformer/Video-Swin-Transformer)ë¥¼ ì°¸ê³ í•˜ì—¬ ì œì‘í–ˆìŠµë‹ˆë‹¤.

## TSN (Temporal Segment Networks)

<aside>
ğŸ’¡ ë¹„ë””ì˜¤ë¥¼ ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆ„ì–´ ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•œ í›„ í†µí•©í•˜ì—¬ í–‰ë™ ì¸ì‹ì„ ìˆ˜í–‰í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸
ì´ ë°©ì‹ì€ ë¹„ë””ì˜¤ì˜ ì‹œê°„ì , ê³µê°„ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë†’ì€ ì¸ì‹ ì„±ëŠ¥ì„ ì œê³µ
</aside>
<br>

ìì„¸í•œ ë‚´ìš©ì€ 
[GitHub - SwinTransformer/Video-Swin-Transformer: This is an official implementation for "Video Swin Transformers](https://github.com/SwinTransformer/Video-Swin-Transformer)
ì„ ì°¸ì¡°í•˜ì„¸ìš”


### ëª©ì°¨
1. [ëª©ì ](#ëª©ì )
2. [ëª¨ë¸](#ëª¨ë¸)
3. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •) 
4. [DATA SET](#data-set) 
5. [Model í•™ìŠµ ë°©ë²•](#model-í•™ìŠµ-ë°©ë²•) 
6. [tester(í…ŒìŠ¤í„°ê¸°)](#testerí…ŒìŠ¤í„°ê¸°) 
7. [recognizor(ì¶”ë¡ ê¸°)](#recognizorì¶”ë¡ ê¸°) 


### ëª©ì 
<aside>
434ê°€ì§€ì˜ ì‚¬ê³  ìœ í˜•ì„ ì¸ì‹í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ í•™ìŠµí•˜ê³ , ì£¼ì–´ì§„ ë¹„ë””ì˜¤ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ê³  ìœ í˜•ì„ íƒì§€í•˜ëŠ” ê²ƒ
</aside>

### ëª¨ë¸
| ëª¨ë¸ ì´ë¦„             | ì •í™•ë„(top1) | ì •í™•ë„(top5) | í‰ê·  ì •í™•ë„(mean1) | ë¡œìŠ¤   | ë©”ëª¨ë¦¬ |
|----------------------|--------------|--------------|--------------------|--------|--------|
| best_model_0522 | 0.2061   | 0.3876       | 0.29685         | 3.6529 | 353 MB |
| best_model_0527 | 0.2304   | 0.4683       | 0.34935         | 3.4279 | 353 MB |
| best_model_0529 | 0.2056   | 0.4503       | 0.0364          | 3.4289 | 353 MB |
| best_model_0531 | 0.1857   | 0.4206       | 0.0333          | 0.3735 | 320 MB |



### í™˜ê²½ ì„¤ì •

mmaction2 ì„¤ì¹˜ ê°€ì´ë“œ

[Installation â€” MMAction2 1.2.0 documentation](https://mmaction2.readthedocs.io/en/latest/get_started/installation.html)

torch+torchvision ì„¤ì¹˜ ë°©ë²•

```bash
##torch+torchvision
pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html
##mmcv ì„¤ì¹˜
pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html

##ì¶”ê°€ ëª¨ë“ˆ ì„¤ì¹˜
pip install opencv-python
pip install timm
pip install scipy
pip install einops

##ì˜¤ë¥˜ ëŒ€ì‘
pip install numpy==1.19.0
```

Docker ì´ë¯¸ì§€
- ë²„ì „ ìˆ˜ì •
    ```bash
    ARG PYTORCH="1.6.0"
    ARG CUDA="10.1"
    ARG CUDNN="7"
    ```
- **Important:**Â Make sure you've installed theÂ [nvidia-container-toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker).
- docker ë¹Œë“œ
    
    ```bash
    # build an image with PyTorch 1.6.0, CUDA 10.1, CUDNN 7.
    docker build -f ./docker/Dockerfile --rm -t mmaction2 .
    
    # docker run --gpus all --shm-size=8g -it -v {DATA_DIR}:/mmaction2/data mmaction2
    docker run --gpus all --shm-size=8g -it -v G:/video_datasets/download_datas:/mmaction2/data mmaction2
    
    pip install mmcv==2.1.0
    pip install -r requirements/build.txt
    python setup.py develop
    
    apt-get update
    apt-get install wget
    ```
    

### DATA SET

- download
    
    [AI-Hub](https://www.aihub.or.kr/devsport/apishell/list.do?currMenu=403&topMenu=100)
    
    ```bash
    export AIHUB_ID=''
    export AIHUB_PW=''
    aihubshell -mode d -datasetkey 597 -filekey 509338
    ```
        

- ë°ì´í„° ì…‹ êµ¬ì„± ë°©ë²•
    
    [https://github.com/SwinTransformer/Video-Swin-Transformer/blob/master/docs/tutorials/3_new_dataset.md](https://github.com/SwinTransformer/Video-Swin-Transformer/blob/master/docs/tutorials/3_new_dataset.md)
    
    - download í´ë” êµ¬ì„±
    
    ```markdown
    ### download ì‹œ                      ### anotation ë³€í™˜
    Root                                 Root
    â”œâ”€â”€ origin                           â”œâ”€â”€ train
    â”‚   â””â”€â”€ subfolder                    â”‚    â””â”€â”€ *.mp4
    â”‚       â””â”€â”€ *.mp4                    â”œâ”€â”€ val
    â”‚                                    â”‚    â””â”€â”€ *.mp4 
    â””â”€â”€ label                            â”œâ”€â”€ test
        â””â”€â”€ subfolder                    â”‚    â””â”€â”€ *.mp4 
    	    â””â”€â”€ *.json                     â”œâ”€â”€ custom_train_mp4.txt
    	                                   â”œâ”€â”€ custom_val_mp4.txt
    	                                   â””â”€â”€ custom_test_mp4.txt
    ```
    
    - video_annotion ë³€í™˜ ë°©ë²•
        - ë³€í™˜ ë°©ë²•
            
            ```bash
            python {Download folder}/convert_video_annotation.py
            ```
            
        - train :  val : test = 70 : 15 : 15 ë¹„ìœ¨ë¡œ ì‘ì„± í•¨
        - videodataset ë°©ì‹ì˜ annotation ì§„í–‰
    - annotation í˜•ì‹
        
        ```
        bb_1_210121_two-wheeled-vehicle_236_21840.mp4 206
        bb_1_211031_two-wheeled-vehicle_241_21549.mp4 232
        bb_1_210125_two-wheeled-vehicle_112_003.mp4 290
        bb_1_210917_two-wheeled-vehicle_121_126.mp4 298
        ...
        ```
        

### Model í•™ìŠµ ë°©ë²•

- tutorial
    
    [Google Colab Tutorial](https://colab.research.google.com/drive/1dLeCGfq3bQFpgtfU5WSPFlvkKsZCWsdo#scrollTo=VcjSRFELVbNk)
    
1. ì‚¬ì „ í•™ìŠµ ëœ TSN ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ(optional)
    
    ```bash
    mkdir checkpoints
    wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \
          -O ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth
    ```
    
2. config ìˆ˜ì • ë° í•™ìŠµ
    
    ```python
    from mmengine import Config
    import os.path as osp
    import mmengine
    from mmengine.runner import Runner
    from mmengine import Config
    from mmengine.runner import set_random_seed
    
    # ì„¤ì • íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    cfg = Config.fromfile('../configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py')
    
    # ë°ì´í„°ì…‹ íƒ€ì…ê³¼ ê²½ë¡œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
    cfg.data_root = '/mmaction2/data/train/'
    cfg.data_root_val = '/mmaction2/data/val/'
    cfg.ann_file_train = '/mmaction2/data/custom_train_mp4.txt'
    cfg.ann_file_val = '/mmaction2/data/custom_val_mp4.txt'
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”ì˜ ë°ì´í„°ì…‹ ì£¼ì„ íŒŒì¼ ë° ë°ì´í„° ê²½ë¡œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
    cfg.test_dataloader.dataset.ann_file = '/mmaction2/data/custom_val_mp4.txt'
    cfg.test_dataloader.dataset.data_prefix.video = '/mmaction2/data/val/'
    
    # í›ˆë ¨ ë°ì´í„° ë¡œë”ì˜ ë°ì´í„°ì…‹ ì£¼ì„ íŒŒì¼ ë° ë°ì´í„° ê²½ë¡œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
    cfg.train_dataloader.dataset.ann_file = '/mmaction2/data/custom_train_mp4.txt'
    cfg.train_dataloader.dataset.data_prefix.video = '/mmaction2/data/train/'
    
    # ê²€ì¦ ë°ì´í„° ë¡œë”ì˜ ë°ì´í„°ì…‹ ì£¼ì„ íŒŒì¼ ë° ë°ì´í„° ê²½ë¡œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
    cfg.val_dataloader.dataset.ann_file = '/mmaction2/data/custom_val_mp4.txt'
    cfg.val_dataloader.dataset.data_prefix.video = '/mmaction2/data/val/'
    
    # ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
    cfg.model.cls_head.num_classes = 434
    
    # ì‚¬ì „ í•™ìŠµëœ TSN ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ##ì´ì–´ì„œ í•™ìŠµ
    # cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'
    
    # íŒŒì¼ê³¼ ë¡œê·¸ë¥¼ ì €ì¥í•  ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    cfg.work_dir = './work_space'
    
    # ì›ë˜ í•™ìŠµë¥ (LR)ì€ 8-GPU í•™ìŠµì„ ìœ„í•´ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    # ìš°ë¦¬ëŠ” 1ê°œì˜ GPUë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— 8ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 16
    cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 16
    cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8 / 16
    cfg.train_cfg.max_epochs = 50
    
    # ë°ì´í„° ë¡œë”ì˜ ì‘ì—…ì ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    cfg.train_dataloader.num_workers = 2
    cfg.val_dataloader.num_workers = 2
    cfg.test_dataloader.num_workers = 2
    
    # í•™ìŠµì„ ìœ„í•œ ë¡œê±°ë¥¼ ì´ˆê¸°í™”í•˜ê³  ìµœì¢… ì„¤ì •ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    print(f'Config:\n{cfg.pretty_text}')
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))
    
    # ì„¤ì •ì—ì„œ ëŸ¬ë„ˆë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.
    runner = Runner.from_cfg(cfg)
    
    # í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.
    runner.train()
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    runner.test()
    ```
    

### tester(í…ŒìŠ¤í„°ê¸°)

```python
from mmaction.apis import inference_recognizer, init_recognizer
from mmengine import Config

# ì„¤ì • íŒŒì¼ì„ ì„ íƒí•˜ê³  ì¸ì‹ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
config = './sample_work/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py'
config = Config.fromfile(config)

# ë¡œë“œí•  ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì„¤ì •í•©ë‹ˆë‹¤.
checkpoint = './sample_work/best_acc_top1_epoch_9.pth'

# ì¸ì‹ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
model = init_recognizer(config, checkpoint, device='cuda:0')

# ì¸ì‹ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
from operator import itemgetter

test_count = 0
total_count = 0
with open("../data/custom_test_mp4.txt", 'r', encoding='utf-8') as file:
    lines = file.readlines()
    total_count = len(lines)

    for line in lines:
        video_name, video_label = line.split()

        # ì˜ˆì¸¡í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        video = '../data/test/'+video_name
        # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
        label = './index_map.txt'

        # ë¹„ë””ì˜¤ì— ëŒ€í•œ ì¸ì‹ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.
        results = inference_recognizer(model, video)

        # ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        pred_scores = results.pred_score.tolist()
        # ì˜ˆì¸¡ ì ìˆ˜ì™€ ì¸ë±ìŠ¤ë¥¼ íŠœí”Œë¡œ ë¬¶ìŠµë‹ˆë‹¤.
        score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))
        # ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•©ë‹ˆë‹¤.
        score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)
        # ìƒìœ„ 5ê°œì˜ ë¼ë²¨ì„ ì„ íƒí•©ë‹ˆë‹¤.
        top5_label = score_sorted[:5]

        # ë¼ë²¨ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
        labels = open(label).readlines()
        # ë¼ë²¨ì—ì„œ ê³µë°± ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        labels = [x.strip() for x in labels]

        # ìƒìœ„ 5ê°œ ë¼ë²¨ê³¼ ì ìˆ˜ë¥¼ ë§¤í•‘í•©ë‹ˆë‹¤.
        results = [(labels[k[0]], k[1]) for k in top5_label]

        # ìƒìœ„ 1ê°œ ê°€ì ¸ì˜¤ê¸°
        print("ì •ë‹µ :"+video_label)
        print(f'{results[0][0]}: ', results[0][1])

        if int(results[0][0]) == int(video_label):
            test_count += 1
print("{}|{} - {}%".format(test_count,total_count,test_count/total_count*100))
```

### recognizor(ì¶”ë¡ ê¸°)

1. config
    - í•™ìŠµ ì‹œ ì‚¬ìš©í•œ workspaceì— ìƒì„±ë˜ì–´ ìˆëŠ”  config íŒŒì¼ ì‚¬ìš©
2. checkpoint 
    - workspaceì— ìƒì„± ëœ best ê°€ì¤‘ì¹˜ ì‚¬ìš©
3. label
    - 0~433, ì´ 434ê°œì˜ ìˆ«ìê°€ â€œ\nâ€ìœ¼ë¡œ ë¶„ë¦¬ëœ íŒŒì¼ë¡œ /data í´ë”ì— ê°™ì´ ì €ì¥ë˜ì–´ ìˆìŒ

```python
from mmaction.apis import inference_recognizer, init_recognizer
from mmengine import Config

# ì„¤ì • íŒŒì¼ì„ ì„ íƒí•˜ê³  ì¸ì‹ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
config = './sample_work/tsn_imagenet-pretrained-r50_8xb32-1x1x8-100e_kinetics400-rgb.py'
config = Config.fromfile(config)

# ë¡œë“œí•  ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì„¤ì •í•©ë‹ˆë‹¤.
checkpoint = './sample_work/best_acc_top1_epoch_8.pth'

# ì¸ì‹ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
model = init_recognizer(config, checkpoint, device='cuda:0')

# ì¸ì‹ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
from operator import itemgetter

# ì˜ˆì¸¡í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
video = './test2_175.mp4'
# ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
label = './index_map.txt'

# ë¹„ë””ì˜¤ì— ëŒ€í•œ ì¸ì‹ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.
results = inference_recognizer(model, video)

# ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
pred_scores = results.pred_score.tolist()
# ì˜ˆì¸¡ ì ìˆ˜ì™€ ì¸ë±ìŠ¤ë¥¼ íŠœí”Œë¡œ ë¬¶ìŠµë‹ˆë‹¤.
score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))
# ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•©ë‹ˆë‹¤.
score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)
# ìƒìœ„ 5ê°œì˜ ë¼ë²¨ì„ ì„ íƒí•©ë‹ˆë‹¤.
top5_label = score_sorted[:5]

# ë¼ë²¨ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
labels = open(label).readlines()
# ë¼ë²¨ì—ì„œ ê³µë°± ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
labels = [x.strip() for x in labels]

# ìƒìœ„ 5ê°œ ë¼ë²¨ê³¼ ì ìˆ˜ë¥¼ ë§¤í•‘í•©ë‹ˆë‹¤.
results = [(labels[k[0]], k[1]) for k in top5_label]

# ìƒìœ„ 5ê°œ ë¼ë²¨ê³¼ í•´ë‹¹ ì ìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
print('The top-5 labels with corresponding scores are:')
for result in results:
    print(f'{result[0]}: ', result[1])
```

ì˜¤ë¥˜ ëª¨ìŒ

1. GPG ì—ëŸ¬
    
    ```bash
    ì˜¤ë¥˜ ë‚´ìš©:
    GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC
    í•´ê²° ë°©ë²•:
    # NVIDIA CUDA ë¦¬í¬ì§€í† ë¦¬ì˜ ê³µê°œ í‚¤ ë‹¤ìš´ë¡œë“œ ë° ì¶”ê°€
    RUN apt-key adv --keyserver keyserver.ubuntu.com --recv-keys A4B469963BF863CC 
    ```
    
    [GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC](https://better-tomorrow.tistory.com/entry/GPG-error-httpsdeveloperdownloadnvidiacomcomputecudareposubuntu1804x8664-InRelease-The-following-signatures-couldnt-be-verified-because-the-public-key-is-not-available-NOPUBKEY-A4B469963BF863CC)
    
2. numpy ë²„ì „ ì—ëŸ¬
    
    ```bash
    ##ì˜¤ë¥˜ ë‚´ìš©
    AttributeError: module 'numpy' has no attribute 'int'.
    `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
    The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
        https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    ```
    
    ```bash
    ##í•´ê²° ë°©ë²•
    pip install numpy==1.19.0
    ```

### version
| ë²„ì „       | ë‚ ì§œ      | ë³€ê²½ ë‚´ìš©                                |
|------------|-------------|------------------------------------------|
|ver 1.0|24.05.26|video-swin-transformerë¥¼ ì´ìš©í•´ ê³¼ì‹¤ ì¸¡ì • ëª¨ë¸ ì œì‘|
|ver 1.1|24.05.26|docker file ìˆ˜ì •|
|ver 1.2|24.05.26|test top5 ì„¹ì…˜ ì¶”ê°€, ëª¨ë¸ ëª… ë³€ê²½|
|ver 1.3|24.05.28|otuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì‘ì„±|
|ver 1.4|24.05.29|best_model_0529 ëª¨ë¸ ì¶”ê°€|
|ver 1.5|24.05.31|best_model_0531 ëª¨ë¸ ì¶”ê°€|